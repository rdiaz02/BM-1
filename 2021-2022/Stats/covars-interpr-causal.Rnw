%% ;;; -*- mode: Rnw; -*-
\synctex=1
\documentclass[a4paper,11pt]{article}
\usepackage{graphics}
\usepackage{amssymb,amsfonts,amsmath,amsbsy}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=28mm,bmargin=28mm,lmargin=30mm,rmargin=30mm}
\usepackage{setspace}
\singlespacing
\usepackage{url}
\usepackage{nameref}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{cancel}
\usepackage{MnSymbol} %% for upmodels, cond, indep.
%% see
%% https://tex.stackexchange.com/questions/3631/is-there-a-standard-symbol-for-conditional-independence
%% https://tex.stackexchange.com/questions/3631/is-there-a-standard-symbol-for-conditional-independence
%% for alternatives
\usepackage{enumitem}
\usepackage[small]{caption}
\usepackage{hyperref}

\hypersetup{
  colorlinks = true,
  citecolor=  black,
  linkcolor = {blue},
  filecolor = cyan %% controls color of external ref, if used
}

\usepackage{color}
\newcommand{\cyan}[1]{{\textcolor {cyan} {#1}}}
\newcommand{\blu}[1]{{\textcolor {blue} {#1}}}
\newcommand{\Burl}[1]{\blu{\url{#1}}}
\newcommand{\red}[1]{{\textcolor {red} {#1}}}
\newcommand{\green}[1]{{\textcolor {green} {#1}}}
\newcommand{\mg}[1]{{\textcolor {magenta} {#1}}}
\newcommand{\og}[1]{{\textcolor {PineGreen} {#1}}}
\newcommand{\code}[1]{\texttt{#1}} %From B. Bolker
\newcommand{\myverb}[1]{{\footnotesize\texttt {\textbf{#1}}}}
\newcommand{\Rnl}{\ +\qquad\ }
\newcommand{\Emph}[1]{\emph{\mg{#1}}}

\newcommand{\activities}{{\textcolor {red} {Activities}}}

\newcommand{\R}{R}

\newcommand{\flspecific}[1]{{\textit{#1}}}

\newcommand*{\qref}[1]{\hyperref[{#1}]{\textit{``\nameref*{#1}'' (section \ref*{#1})}}}


\newcounter{exercise}
\numberwithin{exercise}{section}
\newcommand{\exnumber}{\addtocounter{exercise}{1} \theexercise \thinspace}

\usepackage[copyright]{ccicons}

%% color of links, so it is pink or whatever, and not the kind
%% of boxed with lilght blue, is given by hypersetup
\usepackage[authoryear, round, sort]{natbib}
%% \usepackage[square,numbers,sort&compress]{natbib}

\usepackage{gitinfo}




%% For using listings, so as to later produce HTML
%% uncommented by the make-knitr-hmtl.sh script
%% listings-knitr-html%%\usepackage{listings}
%% listings-knitr-html%%\lstset{language=R}

<<setup,include=FALSE,cache=FALSE>>=
require(knitr)
opts_knit$set(concordance = TRUE)
opts_knit$set(stop_on_error = 2L)
## next are for listings, to produce HTML
##listings-knitr-html%%options(formatR.arrow = TRUE)
##listings-knitr-html%%render_listings()
@

% %% BiocStyle needs to be 1.2.0 or above
% <<packages,echo=FALSE,results='hide',message=FALSE>>=
% require(BiocStyle, quietly = TRUE)
% @ 
% <<style-knitr, eval=TRUE, echo=FALSE, results="asis">>=
% BiocStyle::latex()
% ## or latex(use.unsrturl = FALSE)
% ## to use arbitrary biblio styles
% @



\begin{document}

% \bioctytle
\title{Choosing covariates, interpreting coefficients, and causal inference}

\author{Ramon Diaz-Uriarte\\
  Dept. Biochemistry, Universidad Aut\'onoma de Madrid \\ 
  Instituto de Investigaciones Biom\'edicas ``Alberto Sols'' (UAM-CSIC)\\
  Madrid, Spain{\footnote{r.diaz@uam.es, rdiaz02@gmail.com}} \\
  %% {\footnote{rdiaz02@gmail.com}} \\
  {\small \Burl{http://ligarto.org/rdiaz}} \\
}


\date{\gitAuthorDate\ {\footnotesize (Rev: \gitAbbrevHash)}}



\maketitle

\tableofcontents

\clearpage


\section*{License and copyright}\label{license}
This work is Copyright, \copyright, 2021, Ramon Diaz-Uriarte, and is
licensed under a \textbf{Creative Commons } Attribution-ShareAlike 4.0
International License:
\Burl{http://creativecommons.org/licenses/by-sa/4.0/}.

\centerline \ccbysa



All the original files for the document are available (again, under a Creative
Commons license) from \Burl{https://github.com/rdiaz02/BM-1}. (Note that in the
github repo you will not see the PDF, or R files, nor many of the data files,
since those are derived from the Rnw file). This file is called \texttt{covars-interpr-causal.Rnw}.



\clearpage

\section{Introduction}

The purpose of these notes is to try to clarify the questions about ``what
variables should we add to our models when our aim is interpretation''.

As discussed in class, if our purpose when fitting statistical models is only
prediction, reversal of regression coefficients when a covariate is in the model
with or without other covariates, and other similar counterintuitive phenomena,
are not a problem. The problem can arise if we want to interpret what the
coefficients mean.

The interpretation we often want to give is often a causal one. For example, in a
model where the dependent or outcome variable is cardiovascular health and one of
the predictor variables is red wine we are, arguably, trying to understand if
consuming red wine affects (i.e., has an effect on) cardiovascular health. We
might want to do this so that we can make public health recommendations or take
personal action.  Intuitively, if a variable, X, has an effect (a causal) on a
variable, Y, manipulating X will change the value of Y.


\subsection{There is no such thing as  ``spurious associations''. But when people
  use this term, it shows they are trying to obtain causal estimates}

In the above study, there is a possible obvious problem. Suppose you observe an
association between moderate red wine consumption and better cardiovascular
health. Maybe what is happening is that, in the sample you are using, people who
consume moderate amounts of red wine are also people who consume olive oil and
lots of fresh vegetables (the Mediterranean diet).  The observed association
between red wine consumption and better cardiovascular health is not a causal
association: the association is the result of both red wine consumption and
better cardiovascular health both being effects (or consequences) of the type of
diet. But red wine has no direct effect on cardiovascular health (we will see
examples of this pattern below: \ref{basic-structures})

Some authors would say there is a ``spurious association'' or ``spurious
correlation''\footnote{Instead of ``spurious'' you might read ``illusory'' or
  ``fictitious'' or ``apparent'' or ``misleading''.} between red wine consumption
and health. Well, not really: the association is not spurious. It is quite
real. And there is nothing wrong with computing it, nor with it showing up as
positive. But the association is not causal.

And the reason we can tell ``there is something wrong going on here if we infer
an effect of red wine on health'' is, precisely, because we are trying to use a
model that has causal interpretations. We are trying to answer questions such as
``Is red wine really good for your health?''  or ``Is switching from not
consuming red wine to consuming moderates amount of it a good idea?''. See
\cite[][p.\ 84, for similar comments]{hernan2020}




\activities: Think of at least two examples, ideally at least one related to your
own research, where you might have thought of ``spurious associations''.


<<load_libs, echo=FALSE, results='hide',message=FALSE>>=
## Plots, with dagitty
library(dagitty)

## library(rethinking) ## for drawdag
## Installing rethinking can be complicated just for a few graphs
## So have a fallback if rethinking not available
if(!suppressWarnings(require("rethinking", quietly = TRUE))) {
    drawdag <- plot
} 

library(car)
@ 

\section{Graphs, DAGs, notation}

Graphs, such as the one in \ref{fig:plot_dag_1}, are very useful to represent
causal concepts. In that figure, Age is a \textbf{common cause} of Exercise and
Cholesterol, and Exercise has a direct effect on Cholesterol too.  These are
\textbf{DAG}s, for Directed (i.e., there is direction, and thus we see arrows,
not just edges) Acyclic (there are no cycles: you do not go twice through a
variable if you follow arrows) Graphs.

Sometimes we will use variables denoted as  $U$ (or $U$ with subindices): these
are unobserved variables. 

% Total, direct and indirect effect

\activities: Draw a DAG for the wine, diet, cardiovascular health discussed before.

\section{An introductory example of adjusting for covariates that are common
  causes: Cholesterol, Exercise, Age}


Suppose we sample subjects from a population where, as people get older, they
both exercise more and have higher cholesterol levels. At the same time, for a
given age, the more people exercise, the lower their cholesterol level.  Given a
sample of data where we have collected age, exercise patterns, and cholesterol
levels, how should we analyze the data? (This example is taken from chapter 1,
pp.\ 3 to 5, of \citealp{pearl_causal_2016}). The relationships between the
variables are shown in Figure \ref{fig:plot_dag_1}.



% (Yes, we do know that we should recommend people exercise if they want to lower
% their cholesterol)

<<dag_1, results='hide', echo=FALSE>>=
common_cause <- dagitty("dag {
Age -> Exercise
Age -> Cholesterol
Exercise -> Cholesterol
}")

@ 



%% <<plot_dags_1_2, out.width = '14cm', out.height='7cm'>>=
<<plot_dag_1, fig.width = 4, fig.height=2, fig.lp='fig:', results = 'hide', echo=FALSE, fig.cap='Cholesterol, Exercise, Age example',out.width='10cm'>>=
coordinates(common_cause) <- list(x = c(Exercise = 1, Age = 2, Cholesterol = 3),
                                  y = c(Exercise = 0, Age = -1, Cholesterol = 0))

drawdag(common_cause, xlim = c(0.5, 3.5), ylim = c(0, 1.3))
## text(x = 2, y = 1.2, labels ="a)", cex = 1.2)

@ 

Here I simulate some data that follow the above relationships.  

<<simul_1, results='hide', echo = TRUE>>=
N <- 1e4 
################## Common_cause
common_cause <- data.frame(Age = rnorm(N, 30, 5))
common_cause$Exercise <- 2 * common_cause$Age + rnorm(N)
common_cause$Cholesterol <- 3 * common_cause$Age -
  common_cause$Exercise +
  rnorm(N)

@ 


Before turning the page, think what kind of relationship you expect between
Cholesterol and Exercise in the whole population and between Cholesterol and
Exercise for people of age 10, and for people of age 20, \ldots.


The process above generate data that look like this:


\begin{figure}[h!]
  \centering
  \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{chol-ex1-crop}% first figure itself
%       \caption{first figure}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{chol-ex2-crop} %second figure itself
%       \caption{second figure}
    \end{minipage}
  % \includegraphics[width=0.50\paperwidth,keepaspectratio]{chol-ex1.pdf}
  % \includegraphics[width=0.50\paperwidth,keepaspectratio]{chol-ex2.pdf}
   \caption{\label{fig:chol-exercise-pearl-et-al}. Relationships between
     Cholesterol and Exercise, by age and over the complete population. From
     \citet{pearl_causal_2016}, Figures 1.1. and 1.2 (which are the same as
     Figure 6.6 in \citealp{pearl2018}; a preview of chapter 1 of
     \citealp{pearl_causal_2016} is available from Pearl's page: \Burl{http://bayes.cs.ucla.edu/PRIMER/}). }
\end{figure}
  

\clearpage
Let's analyze the data with and without adjusting for Age
consumption. 


<<code_1, results='show', echo = TRUE>>=
m_common_cause_adjust <- lm(Cholesterol ~ Exercise + Age, data = common_cause)
m_common_cause_no_adjust <- lm(Cholesterol ~ Exercise, data = common_cause)

## Function "S" is from the car library
S(m_common_cause_adjust)
S(m_common_cause_no_adjust)
@

\clearpage


We must adjust (or control) for Age, the common cause of Exercise and Age: if we
don't adjust for Age, the estimate of the effect of Exercise on Cholesterol is
confounded by Age (or by Age having effects on both Exercise and
Cholesterol)\footnote{When dealing with categorical variables, this pattern,
  where the association of two variables changes, or even reverts its sign, when
  we account for another, is also called Simpson's paradox.}.

%% FIXME: maybe this lesson after the one on chi-squares?



\section{Should we always adjust for covariates? Fungus and the post-treatment variable}
\label{fungus-ex}


The following example is modified from \citet[pp.\ 170--174
in][]{rethinking_2020}. An experiment is conducted to asses the effects of an
antifungal treatment (Treatment) on plant final size (Size). The amount of fungus
(a post-treatment variable, Fungus) is also measured. Since plots varied in
quality, in ways that could affect final plant Size, a variable (or variables)
Plot measure the plot quality (pretreament, though this is irrelevant since this
variable, or variables, are not affected by treatment).

The DAG is shown in \ref{fig:dag_fungus_1}

<<dag_fungus_1, results='hide', echo=FALSE>>=
fungus1 <- dagitty("dag {
Treatment -> Fungus
Fungus -> Size
Plot -> Size
}")

@ 

<<plot_fungus_1, fig.width = 4, fig.height=1.4, fig.lp='fig:', results = 'hide', echo=FALSE, fig.cap='Fungus, first example',out.width='9cm'>>=
coordinates(fungus1) <- list(x = c(Treatment = 1, Fungus = 2,
                                        Plot = 2.5,
                                        Size = 3),
                                  y = c(Treatment = -0.5, Fungus = 0,
                                        Plot = -1,
                                        Size = 0))

drawdag(fungus1, xlim = c(0.5, 3.5), ylim = c(-.1, 1.3))
## text(x = 2, y = 1.2, labels ="a)", cex = 1.2)

@ 


%% Write R code for this!

We definitely want to adjust for Plot to reduce the variability in our
estimates. What about Fungus: no, we do not want to adjust for it, as adjusting
for Fungus would actually prevent us from estimating the effect of Treatment:
Treatment affects plant size through Fungus. Once we know about Fungus, Treatment
says nothing about Size \footnote{Size is conditionally independent of Treatment
  given Fungus, $Size \upmodels Treatment | Fungus$. The  $\upmodels$ symbol
  means independence. You can ignore this notation if it does not help you.}.



Even if the true relationship was as shown in \ref{fig:dag_fungus_2} we would not
want to use Fungus as a covariate. Here Treatment is not independent of Size
given Fungus, but Fungus mediates in the relationship. If we added Fungus in the
statistical model, we would not be estimating the total effect of Treatment on
Size (see more details in \qref{direct-indirect}).



<<dag_fungus_2, results='hide', echo=FALSE>>=
fungus2 <- dagitty("dag {
Treatment -> Fungus
Treatment -> Size
Fungus -> Size
Plot -> Size
}")

@ 

<<plot_fungus_2, fig.width = 4, fig.height=1.4, fig.lp='fig:', results = 'hide', echo=FALSE, fig.cap='Fungus, second example',out.width='9cm'>>=
coordinates(fungus2) <- list(x = c(Treatment = 1, Fungus = 2,
                                        Plot = 2.5,
                                        Size = 3),
                                  y = c(Treatment = -0.5, Fungus = 0,
                                        Plot = -1,
                                        Size = 0))

drawdag(fungus2, xlim = c(0.5, 3.5), ylim = c(-.1, 1.3))
## text(x = 2, y = 1.2, labels ="a)", cex = 1.2)

@ 


\section{More fungus: a collider}\label{fungus-collider}

And this example is modified from \citet[p.\ 175 in][]{rethinking_2020}. Suppose
now that Fungus does not affect final Size. But both Fungus  and Size are
affected by moisture (moisture and Plot quality are different
variables). Moreover, and this is crucial, moisture has not been measured, so
there is no way for you to adjust for it, and is shown as U in the DAG below,
Figure \ref{fig:fungus_collider}.


<<dag_fungus_3, results='hide', echo=FALSE>>=
fungus3 <- dagitty("dag {
Treatment -> Fungus
U -> Fungus
U -> Size
Plot -> Size
}")

@ 

<<plot_fungus_3, fig.width = 4, fig.height=1.4, fig.lp='fig:', results = 'hide', echo=FALSE, fig.cap='Fungus, collider example',out.width='9cm'>>=
coordinates(fungus3) <- list(x = c(Treatment = 1,
                                   Fungus = 2,
                                   Plot = 1,
                                   U = 1,
                                   Size = 3),
                             y = c(Treatment = -1.5,
                                   Fungus = -1,
                                   Plot = 0,
                                   U = -0.5,
                                   Size = 0))

drawdag(fungus3, xlim = c(0.5, 3.5), ylim = c(-.1, 1.6))
## text(x = 2, y = 1.2, labels ="a)", cex = 1.2)

@ 

In the above figure, Fungus is a descendant of both U and Treatment. This is
called a \textbf{collider}. Conditioning on Fungus will lead to Treatment and
moisture (U) being associated, even when they are really independent of each
other. And that would lead to our mistakenly estimating that Treatment has an
effect on Size (U affects Size and U is associated with Treatment when we
condition on Fungus), when Treatment really does not have an effect on Size.

OK, this is getting complicated. Let us see the three basic DAG structures,
and a few derived ones.


(But before we leave this example: what should we have done? Include in the model
Treatment, which is the variable we are interested in, and also Plot, to decrease
variability of the estimates. If we could we could have adjusted for U it would
have been good, but we can't; anyway, U will increase the variability, but will
not lead to bias. The bad idea was adjusting for Fungus.)

\section{Basic DAG structures}\label{dag-structs}

The basic DAG structures with their names are presented in Figure
\ref{fig:plot_dag_struct}\footnote{This is fairly standard material; you can find it in,
for example, Figure 3.3 in \citet{morgan_counterfactuals_2015}, section 6.3 in
\citet{hernan2020}, sections 2.2. and 2.3 in \citet{pearl_causal_2016}, Figure
8.1 in \citet{kline2015}}.




<<dag_struct, results='hide', echo=FALSE>>=
chain <- dagitty("dag {
X -> Z
Z -> Y
}")

fork <- dagitty("dag {
Z -> X
Z -> Y
}")

collider <- dagitty("dag {
X -> Z
Y -> Z
}")

@ 

<<plot_dag_struct, fig.width = 5, fig.height=1.5, fig.lp='fig:', results = 'hide', echo=FALSE, fig.cap='Basic DAG structures',out.width='11cm'>>=
op <- par(mfrow = c(1, 3))

coordinates(chain) <- list(x = c(X = 1,
                                 Y = 3,
                                 Z = 2),
                           y = c(X = 0,
                                 Y = 0,
                                 Z = 0))

coordinates(fork) <- list(x = c(X = 1,
                                 Y = 3,
                                 Z = 2),
                           y = c(X = 0,
                                 Y = 0,
                                 Z = -.50))

coordinates(collider) <- list(x = c(X = 1,
                                 Y = 3,
                                 Z = 2),
                           y = c(X = -.5,
                                 Y = -.5,
                                 Z = 0))



drawdag(chain, xlim = c(0.5, 3.5), ylim = c(-1, 1.3))
text(x = 2, y = -.8, labels ="a) Chain.\n Z mediates", cex = 1.1)


drawdag(fork, xlim = c(0.5, 3.5), ylim = c(-1, 1.3))
text(x = 2, y = -.8, labels ="b) Fork.\n Z common cause", cex = 1.1)


drawdag(collider, xlim = c(0.5, 3.5), ylim = c(-1, 1.3))
text(x = 2.1, y = -.8, labels ="c) Inverted fork with collider.\n Z common effect (collider)", cex = 1.1)

@ 


Each of those structures determines the relationships or pattern of association
between variables.  For example, in the Chain case, we know that X causes Z that
causes Y. Those are the causal relationships. Now, what \textbf{associations}
will we observe? You can think of the DAGs as pipes, and association flows (or
not) through these pipes (see \citealp[ch.~6 in]{hernan2020}; in Miguel Hern\'an's
edX
course ``Causal Diagrams: Draw Your Assumptions Before Your Conclusions''\\
\Burl{https://www.edx.org/course/causal-diagrams-draw-your-assumptions-before-your},
you can see animations of this process).  A mediator or common cause, if
conditioned upon, blocks the flow of information because it closes the pipe; in
contrast, a collider, if conditioned upon, opens the pipe.

Put it differently, in the chain example in Figure \ref{fig:plot_dag_struct}, if
we do not condition in Z, the pipe is open, so X and Y are
associated\footnote{Strictly: ``are very likely associated'' as it could happen
  that they are not, but this would be rare}. But if we condition on Z, we close
the pipe, the flow of association, and now X and Y are conditionally independent
given Z.


More systematically: 
\begin{enumerate}[label=\alph*]

\item Chain: X and Y are associated. But conditioning on Z will render X and Y
  independent (there will be no association). The conditional and unconditional
  dependencies are (you can ignore this if it does not help you):
  $X \upmodels Y | Z$, \quad $X \cancel{\upmodels} Y$.

\item Fork: X and Y are associated. But conditioning on Z will render X and Y
  independent (there will be no association). $X \upmodels Y | Z$, \quad
  $X \cancel{\upmodels} Y$.


\item Inverted fork with collider: X and Y are independent. But conditioning on Z will make X and Y associated
  (if these were numerical variables and we assume a linear model, they would
  show a correlation).  $X \cancel{\upmodels} Y | Z$, \quad $X \upmodels Y$.
   
  
\end{enumerate}


%% ZZ FIXME : give the example of Y must compensate whatever X has
The consequences of the last structure, the collider or inverted fork, sometimes
seem counterintuitive. This structure is behind ``Berkson's paradox'' \footnote{
  \Burl{https://en.wikipedia.org/wiki/Berkson\%27s_paradox}, and it might explain
  ``Why are handsome men such jerks?'':
  \Burl{http://www.slate.com/blogs/how_not_to_be_wrong/2014/06/03/berkson_s_fallacy_why_are_handsome_men_such_jerks.html}
  ---and, I guess, a similar phenomenon with women.}. A simple example: suppose
there is no association between bone fracture and pneumonia in the general
population. But if you only look at people who go to the emergency room in a
hospital, you are likely to find a negative association between pneumonia and
bone fracture (think about why people go to hospitals ---there must be some
reason to be in the hospital to begin with, and either severe pneumonia or a
broken bone are enough to take you there). If this example is not clear, look at
the Wikipedia entry linked in the footnotes (or the ``Why are handsome men such
jerks'', linked in the footnote too). Conditioning (and restricting) on colliders
leads to \textbf{selection bias} (see chapters 7 and 8 in \citealp{hernan2020})

\activities: Think of at least one example for each of the structures
above. \textbf{Really, do it}. Ideally, think of two examples, one from
``everyday life'' and one from you scientific work/TFM/etc.


\subsection{Variance and bias, or random and systematic error}
Westreich, pp. 24 and 25. (relationship to notions of validity and precision,
though I prefer to use bias and variance)

Bias: ``sesgo'', in Spanish


\section{Basic structures}
%% Rethinking, p. 180
%% Probably in many other places too: refer to those
M and Winship: p. 82

%% Use enumerate here

Fork,
Pipe, (?): chain in Pearl et al. pp. 38 to 41
Collider

Do not use ``pipe''. Reserve pipe for the path, that is then opened or closed to
the flow of association.

Mention Berkson's, in footnote. (and why handsome men are jerks)


\subsection{Descendants and ancestors in the derived structures}
%% Modified

Descendant of collider
Ancestor of fork
Ancestor of pipe
Descendant of fork
Descendant of pipe
%% Use enumerate here


\section{The examples}

\subsection{}


Z -> X -> Y

cite Vanderweele and Shpitser, 2011. Also Ewel?


\subsection{A more complex, but very real, example: the birth-weight paradox}



In designed experiments with random assignment of experimental units (patients,
petri dishes, whatever) to treatments, there is no
confounding\footnote{Randomization leads to exchangeability: there is no
  association between the potential outcomes and the actual treatment received.
  The relationship between randomization and exchangeability is discussed in
  ``Technical Point 2.1'', p.\ 15 in \citet{hernan2020}.  An intuitive
  explanation (for a treatment with two possible values, ``treatment'' and
  ``control'') is the following one in section 2.3.2, p.\ 9 of \cite{neal_causality_2020}:
  ``Exchangeability means that the treatment groups are exchangeable in the sense
  that if they were swapped, the new treatment group would observe the same
  outcomes as the old treatment group, and the new control group would observe
  the same outcomes as the old control group. ''

  We are ignoring other issues, such as partial compliance
  and whether to use ``intention to treat'' or ``per-protocol'' analyses; see
  chapter 9 in \citet{hernan2020}. Note that differential loss to follow up is a
  case of selection bias, not confounding; see chapter 8 in
  \citet{hernan2020}. On both issues, see also chapter 5 in
  \citet{westreich2019}.

  
  More on ``exchangeability''. What follows is just for completeness, and because
  I tend to trip over terminological issues.  As explained in pp.\ 459 and 460 of
  \cite{vanderweele2015}, the same condition is often referred to by the
  following different names: ``exchangeability'', ``ignorability'',
  ``exogeneity'' or ``no-unmeasured-confounding''. For example,
  \citet{morgan_counterfactuals_2015} in p.\ 53 (section 2.6) use
  ``ignorability'' for the same expression used to denote exchangeability in
  \citet{hernan2020}, and \citet{pearl_causality_2009} in pp.79 and 341-342
  also uses ``ignorability'' for the same expression (more precisely, Pearl's
  expression is for conditional exchangeability given covariates Z).
  \citet{rosenbaum2017} defines ignorability in note 33, p.\ 300, and p.\ 349,
  with the emphasis the other way around: probability of treatment assignment
  independent of potential outcomes given covariates. % But then,
  % \citet{Gelman2014} in exercise 8.10, p.\ 230, have an exercise where we are
  % asked to explain the differences --I think their usage of e
  % The reasons for receiving one treatment or another cannot be due to the outcome
  % itself nor to the treatment actually received.
}.

%% It would be great to clarify this terminological inconsistency.
%% Rosenbaum's definition is awesome, but is really about ignorability, which
%% I think is not exactly the same as exchangeability in Hernan and Robins.
% More formally, we would say there is exchangeability; see
% chapters 2 and 3 in \citet{hernan2020} and note 33, p.\ 300, in
% \citet{rosenbaum2017}.
%% Gelman et al also discuss this, but I think their use of exchangeability is different.


\section{Direct and indirect effects}\label{direct-indirect}


\subsection{Cholesterol, exercise, food}
Look now at the relationship depicted in Figure \ref{fig:plot_dags_1_2}, panel
``b)'', and suppose that, even if Exercise directly leads to a decrease in
Cholesterol, Exercise also leads to an increase in Food consumption and
increasing Food consumption (because of the low quality of food available) leads
to an increase in Cholesterol. How would we analyze this data if we want to
estimate the total effect of Exercise on Cholesterol?



<<dag_2, results='hide', echo = FALSE>>=
mediator <- dagitty("dag {
Exercise -> Food
Food -> Cholesterol
Exercise -> Cholesterol
}")
@ 
%% <<plot_dags_1_2, out.width = '14cm', out.height='7cm'>>=
<<plot_direct_chol_food, fig.width = 10, fig.height=5, fig.lp='fig:', results = 'hide', echo=FALSE, fig.cap='Introductory figures'>>=
coordinates(common_cause) <- list(x = c(Exercise = 1, Age = 2, Cholesterol = 3),
                                  y = c(Exercise = 0, Age = -1, Cholesterol = 0))

drawdag(mediator, xlim = c(0.5, 3.5), ylim = c(0, 1.3))
text(x = 2, y = 1.2, labels ="b)", cex = 1.2)
@ 


<<simul_2, results='hide', echo = TRUE>>=
N <- 1e4 

################## Mediator
mediator <- data.frame(Exercise = runif(N, 1, 100))
mediator$Food <- mediator$Exercise * 3 + rnorm(N)
## Cholesterol decreases with Exercise (-1) but increases with Food
mediator$Cholesterol <- mediator$Food * 2 - mediator$Exercise + rnorm(N)
@ 

And here for case b).
<<code_2, results='show', echo = TRUE>>=
m_mediator_adjust <- lm(Cholesterol ~ Exercise + Food, data = mediator)
m_mediator_no_adjust <- lm(Cholesterol ~ Exercise, data = mediator)

S(m_mediator_adjust)
S(m_mediator_no_adjust)

@ 

In case b), if we want to measure the total
effect of Exercise in this experiment, we should not adjust for Food
consumption.

\section{How is all of this relevant if I only do experimental/observational
  work?}

\section{Extra: Lord's paradox}

This is not required material, but \citet{pearl2016} presents a very interesting
analysis of what is  called Lord's paradox\footnote{This same paradox has
  been presented in many different places by other authors, and also by Pearl in
  other work; but the presentation in \citealp{pearl2016} I find much, much,
  clearer and insightful than the one in p.\ 85 of \citealp{pearl_causal_2016} or
  pp.\ 212-215 ---chapter 6--- of \citealp{pearl2018}}.

As Pearl explains, his paper ``address(es) the general methodological issue of
whether adjustments for preexisting conditions is justified in group comparison
applications''. A nice feature of this paper is that Pearl presents both the
original paradox as written by Lord as well as some later modifications. Some of
the versions differ because in the original one we have a mediation problem,
whereas in the second we have a confounding problem. Even if the structure of the
different presentations can seem misleadingly similar, they are fundamentally
different. In the mediation case, whether or not to adjust for covariates depends
on whether we want the direct effect (this is what we would get if we adjust for
the covariate) or the total effect (what we get when we don't). In the
confounding case, of course, we must adjust for the covariate.


{\small
  %% \bibliography{extracted-bib}
  \bibliography{refs}
  \bibliographystyle{myplainnat}
  %% \bibliographystyle{mybibwithurl} %% not compatible with author-year
}



\end{document}




